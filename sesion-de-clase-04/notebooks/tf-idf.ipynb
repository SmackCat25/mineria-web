{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-10T02:45:39.017592Z",
     "start_time": "2025-09-10T02:45:37.789656Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import spacy\n",
    "import nltk"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T02:45:53.183857Z",
     "start_time": "2025-09-10T02:45:49.376227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "!py -m spacy download es_core_news_sm"
   ],
   "id": "d8cae6cc5dae67c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aml\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aml\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aml\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     --------------------------------------  12.8/12.9 MB 82.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 40.3 MB/s eta 0:00:00\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\aml\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T02:46:03.495335Z",
     "start_time": "2025-09-10T02:46:03.297693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "stop_words = set(nltk.corpus.stopwords.words('spanish'))"
   ],
   "id": "657ad6c8e452a7c2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T02:46:07.100187Z",
     "start_time": "2025-09-10T02:46:07.096598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_text(documents):\n",
    "    \"\"\"\n",
    "    Normaliza una lista de documentos eliminando puntuación, convirtiendo a minúsculas,\n",
    "    eliminando stopwords y lematizando.\n",
    "\n",
    "    Args:\n",
    "        documents (list): Una lista de cadenas de texto.\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de documentos normalizados.\n",
    "    \"\"\"\n",
    "    normalized_list = []\n",
    "    for doc in documents:\n",
    "        # Pasa el documento completo por el pipeline de spaCy\n",
    "        processed_doc = nlp(re.sub(r'[^\\w\\s]', '', doc.lower()))\n",
    "\n",
    "        # Filtra tokens para lematizar, eliminando stopwords y no alfabéticos\n",
    "        normalized_words = [\n",
    "            token.lemma_ for token in processed_doc\n",
    "            if token.is_alpha and token.text not in stop_words\n",
    "        ]\n",
    "        # Une las palabras normalizadas en una sola cadena\n",
    "        normalized_list.append(\" \".join(normalized_words))\n",
    "    return normalized_list\n"
   ],
   "id": "b602eb21567cd63",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T02:46:18.275329Z",
     "start_time": "2025-09-10T02:46:18.261501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Documentos de entrada\n",
    "corpus = [\n",
    "    \"El gato negro salta sobre la mesa.\",\n",
    "    \"El perro salta sobre la cerca.\"\n",
    "]\n",
    "\n",
    "# Normaliza los documentos\n",
    "normalized_corpus = normalize_text(corpus)\n",
    "print(\"Documentos normalizados:\\n\", normalized_corpus)\n",
    "\n",
    "# Implementa el modelo TF-IDF\n",
    "# Crea una instancia de TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transforma los documentos normalizados en una matriz de valores TF-IDF\n",
    "# fit_transform() aprende el vocabulario y crea la matriz en un solo paso\n",
    "tfidf_matrix = vectorizer.fit_transform(normalized_corpus)\n",
    "\n",
    "# Obtiene el vocabulario único\n",
    "vocabulario = vectorizer.get_feature_names_out()\n",
    "print(\"\\nVocabulario (palabras únicas):\\n\", vocabulario)\n",
    "\n",
    "# Convierte la matriz dispersa a un array denso para una mejor visualización\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Muestra la matriz resultante en un DataFrame de Pandas para mayor claridad\n",
    "df_tfidf = pd.DataFrame(tfidf_array, columns=vocabulario, index=[f\"Documento {i+1}\" for i in range(len(corpus))])\n",
    "print(\"\\nMatriz de TF-IDF (valores de importancia):\\n\")\n",
    "print(df_tfidf)"
   ],
   "id": "2739581843e35102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos normalizados:\n",
      " ['gato negro salta mesa', 'perro salta cerca']\n",
      "\n",
      "Vocabulario (palabras únicas):\n",
      " ['cerca' 'gato' 'mesa' 'negro' 'perro' 'salta']\n",
      "\n",
      "Matriz de TF-IDF (valores de importancia):\n",
      "\n",
      "                cerca      gato      mesa     negro     perro     salta\n",
      "Documento 1  0.000000  0.534046  0.534046  0.534046  0.000000  0.379978\n",
      "Documento 2  0.631667  0.000000  0.000000  0.000000  0.631667  0.449436\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
