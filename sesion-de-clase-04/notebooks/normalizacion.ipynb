{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"initial_id\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-10T02:19:26.739498Z\",\n",
    "     \"start_time\": \"2025-09-10T02:19:26.216193Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"import nltk\\n\",\n",
    "    \"nltk.download('stopwords')\\n\",\n",
    "    \"nltk.download('punkt')\\n\",\n",
    "    \"nltk.download(\\\"punkt_tab\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"import spacy\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[nltk_data] Downloading package stopwords to\\n\",\n",
    "      \"[nltk_data]     C:\\\\Users\\\\aml\\\\AppData\\\\Roaming\\\\nltk_data...\\n\",\n",
    "      \"[nltk_data]   Package stopwords is already up-to-date!\\n\",\n",
    "      \"[nltk_data] Downloading package punkt to\\n\",\n",
    "      \"[nltk_data]     C:\\\\Users\\\\aml\\\\AppData\\\\Roaming\\\\nltk_data...\\n\",\n",
    "      \"[nltk_data]   Package punkt is already up-to-date!\\n\",\n",
    "      \"[nltk_data] Downloading package punkt_tab to\\n\",\n",
    "      \"[nltk_data]     C:\\\\Users\\\\aml\\\\AppData\\\\Roaming\\\\nltk_data...\\n\",\n",
    "      \"[nltk_data]   Package punkt_tab is already up-to-date!\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 2\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-10T02:21:09.656819Z\",\n",
    "     \"start_time\": \"2025-09-10T02:21:05.609304Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"!py -m spacy download es_core_news_sm\",\n",
    "   \"id\": \"3dfb8d4fbf40a48\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Collecting es-core-news-sm==3.8.0\\n\",\n",
    "      \"  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\\n\",\n",
    "      \"     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\\n\",\n",
    "      \"     --------------------------------------  12.8/12.9 MB 81.7 MB/s eta 0:00:01\\n\",\n",
    "      \"     --------------------------------------- 12.9/12.9 MB 41.6 MB/s eta 0:00:00\\n\",\n",
    "      \"Installing collected packages: es-core-news-sm\\n\",\n",
    "      \"Successfully installed es-core-news-sm-3.8.0\\n\",\n",
    "      \"\\u001B[38;5;2m✔ Download and installation successful\\u001B[0m\\n\",\n",
    "      \"You can now load the package via spacy.load('es_core_news_sm')\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"[notice] A new release of pip is available: 25.1.1 -> 25.2\\n\",\n",
    "      \"[notice] To update, run: C:\\\\Users\\\\aml\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe -m pip install --upgrade pip\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 6\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-10T02:21:12.165452Z\",\n",
    "     \"start_time\": \"2025-09-10T02:21:11.914343Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"nlp = spacy.load(\\\"es_core_news_sm\\\")\\n\",\n",
    "    \"stop_words = set(nltk.corpus.stopwords.words('spanish'))\"\n",
    "   ],\n",
    "   \"id\": \"deed73135fa2aebc\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 7\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-10T02:21:13.053569Z\",\n",
    "     \"start_time\": \"2025-09-10T02:21:13.050322Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"import re\\n\",\n",
    "    \"\\n\",\n",
    "    \"def normalize_text(text):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Normaliza un texto largo aplicando lematización, eliminación de stopwords y puntuación.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        text: El texto de entrada a normalizar.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        list: Una lista de palabras normalizadas.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Conversión a minúsculas y eliminación de puntuación\\n\",\n",
    "    \"    # Esta línea simplifica el texto antes de procesarlo\\n\",\n",
    "    \"    processed_text = re.sub(r'[^\\\\w\\\\s]', '', text.lower())\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 2. Tokenización y Lematización con spaCy\\n\",\n",
    "    \"    doc = nlp(processed_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 3. Eliminar stopwords y palabras que no son alfabéticas\\n\",\n",
    "    \"    normalized_words = [\\n\",\n",
    "    \"        token.lemma_ for token in doc\\n\",\n",
    "    \"        if token.is_alpha and token.text not in stop_words\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return normalized_words\"\n",
    "   ],\n",
    "   \"id\": \"b071005e33b8dfeb\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 8\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-10T02:21:15.523986Z\",\n",
    "     \"start_time\": \"2025-09-10T02:21:15.513141Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"long_text = \\\"\\\"\\\"\\n\",\n",
    "    \"Las computadoras están corriendo muy rápido y son importantes para el análisis de los datos.\\n\",\n",
    "    \"Nosotros estábamos analizando unos datos interesantes.\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"normalized_list = normalize_text(long_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Muestra el texto original y el texto normalizado\\n\",\n",
    "    \"print(\\\"Texto original:\\\")\\n\",\n",
    "    \"print(long_text)\\n\",\n",
    "    \"print(\\\"\\\\n--- Texto Normalizado (lista de palabras) ---\\\")\\n\",\n",
    "    \"print(normalized_list)\"\n",
    "   ],\n",
    "   \"id\": \"d594534a9c01cff8\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Texto original:\\n\",\n",
    "      \"\\n\",\n",
    "      \"Las computadoras están corriendo muy rápido y son importantes para el análisis de los datos.\\n\",\n",
    "      \"Nosotros estábamos analizando unos datos interesantes.\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"--- Texto Normalizado (lista de palabras) ---\\n\",\n",
    "      \"['computadora', 'correr', 'rápido', 'importante', 'análisis', 'dato', 'analizar', 'dato', 'interesante']\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 9\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "2293de5f3f5823f"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
